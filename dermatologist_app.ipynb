{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 total lesion types.\n",
      "There are 450 total lesion images.\n",
      "\n",
      "There are 150 training lesion images.\n",
      "There are 150 validation lesion images.\n",
      "There are 150 test lesion images.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']))\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('data/train')\n",
    "valid_files, valid_targets = load_dataset('data/valid')\n",
    "test_files, test_targets = load_dataset('data/test')\n",
    "\n",
    "# load list of lesion types\n",
    "lesion_types = [item[11:-1] for item in sorted(glob(\"data/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total lesion types.' % len(lesion_types))\n",
    "print('There are %s total lesion images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training lesion images.' % len(train_files))\n",
    "print('There are %d validation lesion images.' % len(valid_files))\n",
    "print('There are %d test lesion images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "def extract_VGG16(tensor):\n",
    "\tfrom keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\treturn VGG16(weights='imagenet', include_top=False).predict(preprocess_input(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86645c03f5444ec1881b280234ba312e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d9701e8803439283f6b0e6230bc54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f73eb816ec47418c8c0e40db4be156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define Model Architecture - From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 128)       32896     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 51,891\n",
      "Trainable params: 51,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "scratch_model = Sequential()\n",
    "scratch_model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "scratch_model.add(MaxPooling2D(pool_size=2))\n",
    "scratch_model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "scratch_model.add(MaxPooling2D(pool_size=2))\n",
    "scratch_model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "scratch_model.add(MaxPooling2D(pool_size=2))\n",
    "scratch_model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "scratch_model.add(GlobalAveragePooling2D())\n",
    "scratch_model.add(Dense(64, activation='relu'))\n",
    "scratch_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "scratch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 1.0105 - acc: 0.5357Epoch 00001: val_loss improved from inf to 1.01383, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 9s 62ms/step - loss: 1.0262 - acc: 0.5200 - val_loss: 1.0138 - val_acc: 0.5200\n",
      "Epoch 2/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 1.0112 - acc: 0.5214Epoch 00002: val_loss improved from 1.01383 to 1.00941, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 9s 63ms/step - loss: 1.0110 - acc: 0.5200 - val_loss: 1.0094 - val_acc: 0.5200\n",
      "Epoch 3/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9938 - acc: 0.5357Epoch 00003: val_loss improved from 1.00941 to 1.00064, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 1.0105 - acc: 0.5200 - val_loss: 1.0006 - val_acc: 0.5200\n",
      "Epoch 4/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 1.0063 - acc: 0.5143Epoch 00004: val_loss improved from 1.00064 to 0.99287, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 10s 67ms/step - loss: 0.9998 - acc: 0.5200 - val_loss: 0.9929 - val_acc: 0.5200\n",
      "Epoch 5/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9889 - acc: 0.5214Epoch 00005: val_loss improved from 0.99287 to 0.98412, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.9970 - acc: 0.5200 - val_loss: 0.9841 - val_acc: 0.5200\n",
      "Epoch 6/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9869 - acc: 0.5286Epoch 00006: val_loss improved from 0.98412 to 0.97550, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.9867 - acc: 0.5200 - val_loss: 0.9755 - val_acc: 0.5200\n",
      "Epoch 7/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9849 - acc: 0.5000Epoch 00007: val_loss improved from 0.97550 to 0.96988, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.9752 - acc: 0.5200 - val_loss: 0.9699 - val_acc: 0.5200\n",
      "Epoch 8/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9677 - acc: 0.5286Epoch 00008: val_loss improved from 0.96988 to 0.96115, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.9704 - acc: 0.5267 - val_loss: 0.9612 - val_acc: 0.5400\n",
      "Epoch 9/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9682 - acc: 0.5143Epoch 00009: val_loss did not improve\n",
      "150/150 [==============================] - 9s 62ms/step - loss: 0.9609 - acc: 0.5200 - val_loss: 0.9884 - val_acc: 0.5200\n",
      "Epoch 10/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9947 - acc: 0.5071Epoch 00010: val_loss did not improve\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 0.9887 - acc: 0.5200 - val_loss: 0.9877 - val_acc: 0.5533\n",
      "Epoch 11/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9814 - acc: 0.5429Epoch 00011: val_loss improved from 0.96115 to 0.95204, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 9s 62ms/step - loss: 0.9850 - acc: 0.5467 - val_loss: 0.9520 - val_acc: 0.5333\n",
      "Epoch 12/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9356 - acc: 0.5357Epoch 00012: val_loss improved from 0.95204 to 0.94587, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 9s 62ms/step - loss: 0.9560 - acc: 0.5200 - val_loss: 0.9459 - val_acc: 0.5333\n",
      "Epoch 13/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9260 - acc: 0.5571Epoch 00013: val_loss improved from 0.94587 to 0.93197, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.9396 - acc: 0.5400 - val_loss: 0.9320 - val_acc: 0.5600\n",
      "Epoch 14/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9604 - acc: 0.5429Epoch 00014: val_loss did not improve\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 0.9544 - acc: 0.5467 - val_loss: 0.9340 - val_acc: 0.5467\n",
      "Epoch 15/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9219 - acc: 0.5429Epoch 00015: val_loss improved from 0.93197 to 0.90396, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.9169 - acc: 0.5467 - val_loss: 0.9040 - val_acc: 0.5533\n",
      "Epoch 16/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9436 - acc: 0.5571Epoch 00016: val_loss did not improve\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 0.9425 - acc: 0.5400 - val_loss: 0.9188 - val_acc: 0.6067\n",
      "Epoch 17/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.9372 - acc: 0.5643Epoch 00017: val_loss did not improve\n",
      "150/150 [==============================] - 10s 63ms/step - loss: 0.9370 - acc: 0.5800 - val_loss: 0.9074 - val_acc: 0.5733\n",
      "Epoch 18/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.8871 - acc: 0.5357Epoch 00018: val_loss did not improve\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.8819 - acc: 0.5467 - val_loss: 0.9062 - val_acc: 0.5467\n",
      "Epoch 19/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.8923 - acc: 0.5429Epoch 00019: val_loss improved from 0.90396 to 0.86697, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.8882 - acc: 0.5533 - val_loss: 0.8670 - val_acc: 0.5533\n",
      "Epoch 20/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.8766 - acc: 0.5429Epoch 00020: val_loss improved from 0.86697 to 0.86511, saving model to saved_models/scratch.weights.best.hdf5\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.8720 - acc: 0.5467 - val_loss: 0.8651 - val_acc: 0.5400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a50bc2400>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "n_epochs=20\n",
    "\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/scratch.weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "scratch_model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=n_epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_model.load_weights('saved_models/scratch.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 54.0000%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "lesion_predictions = [np.argmax(scratch_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(lesion_predictions)==np.argmax(test_targets, axis=1))/len(lesion_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing bottleneck features - Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dccedd191454443873379102f190c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing bottleneck features - Valid\n",
      "Preprocessing bottleneck features - Test\n"
     ]
    }
   ],
   "source": [
    "# create bottleneck feature\n",
    "bottleneck_features = dict()\n",
    "\n",
    "print(\"Preprocessing bottleneck features - Train\")\n",
    "bottleneck_features['train'] = np.concatenate([extract_VGG16(path_to_tensor(img_path)) for img_path in tqdm(train_files)])\n",
    "\n",
    "print(\"Preprocessing bottleneck features - Valid\")\n",
    "bottleneck_features['valid'] = np.concatenate([extract_VGG16(path_to_tensor(img_path)) for img_path in tqdm(valid_files)])\n",
    "\n",
    "print(\"Preprocessing bottleneck features - Test\")\n",
    "bottleneck_features['test'] = np.concatenate([extract_VGG16(path_to_tensor(img_path)) for img_path in tqdm(test_files)])\n",
    "\n",
    "# store to file by savez\n",
    "os.makedirs(\"bottleneck_features\", exist_ok=True)\n",
    "np.savez('bottleneck_features/LesionVGG16Data', \n",
    "         train=bottleneck_features['train'], \n",
    "         valid=bottleneck_features['valid'],\n",
    "         test=bottleneck_features['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = np.load('bottleneck_features/LesionVGG16Data.npz')\n",
    "train_VGG16 = bottleneck_features['train']\n",
    "valid_VGG16 = bottleneck_features['valid']\n",
    "test_VGG16 = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Architecture - Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,605,891\n",
      "Trainable params: 1,605,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "VGG16_model = Sequential()\n",
    "\n",
    "VGG16_model.add(Flatten(input_shape=train_VGG16.shape[1:]))\n",
    "VGG16_model.add(Dense(64, activation='relu'))\n",
    "VGG16_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 5.7141 - acc: 0.5429Epoch 00001: val_loss improved from inf to 4.86686, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 5.8903 - acc: 0.5200 - val_loss: 4.8669 - val_acc: 0.6733\n",
      "Epoch 2/20\n",
      "120/150 [=======================>......] - ETA: 0s - loss: 4.0784 - acc: 0.7250Epoch 00002: val_loss improved from 4.86686 to 4.49318, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 4.2028 - acc: 0.7067 - val_loss: 4.4932 - val_acc: 0.7067\n",
      "Epoch 3/20\n",
      "120/150 [=======================>......] - ETA: 0s - loss: 5.6211 - acc: 0.6083Epoch 00003: val_loss did not improve\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 5.4640 - acc: 0.6267 - val_loss: 4.7088 - val_acc: 0.6867\n",
      "Epoch 4/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 4.3883 - acc: 0.7143Epoch 00004: val_loss improved from 4.49318 to 3.72535, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 4.1014 - acc: 0.7267 - val_loss: 3.7253 - val_acc: 0.7533\n",
      "Epoch 5/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 3.9648 - acc: 0.7500Epoch 00005: val_loss improved from 3.72535 to 3.39522, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 3.7199 - acc: 0.7600 - val_loss: 3.3952 - val_acc: 0.7667\n",
      "Epoch 6/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 3.7464 - acc: 0.7286Epoch 00006: val_loss improved from 3.39522 to 3.10409, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 3.6041 - acc: 0.7400 - val_loss: 3.1041 - val_acc: 0.7933\n",
      "Epoch 7/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 3.1508 - acc: 0.7857Epoch 00007: val_loss improved from 3.10409 to 2.90177, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 3.2632 - acc: 0.7800 - val_loss: 2.9018 - val_acc: 0.8133\n",
      "Epoch 8/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.8770 - acc: 0.8071Epoch 00008: val_loss improved from 2.90177 to 2.47541, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 2.7927 - acc: 0.8133 - val_loss: 2.4754 - val_acc: 0.8467\n",
      "Epoch 9/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.4265 - acc: 0.8429Epoch 00009: val_loss improved from 2.47541 to 2.42051, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.4796 - acc: 0.8400 - val_loss: 2.4205 - val_acc: 0.8400\n",
      "Epoch 10/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.5197 - acc: 0.8357Epoch 00010: val_loss did not improve\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4592 - acc: 0.8400 - val_loss: 2.5189 - val_acc: 0.8400\n",
      "Epoch 11/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.6340 - acc: 0.8286Epoch 00011: val_loss did not improve\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4584 - acc: 0.8400 - val_loss: 2.7708 - val_acc: 0.8267\n",
      "Epoch 12/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 3.0208 - acc: 0.8071Epoch 00012: val_loss did not improve\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.8194 - acc: 0.8200 - val_loss: 2.7520 - val_acc: 0.8267\n",
      "Epoch 13/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.6510 - acc: 0.8286Epoch 00013: val_loss improved from 2.42051 to 2.38224, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.5817 - acc: 0.8333 - val_loss: 2.3822 - val_acc: 0.8467\n",
      "Epoch 14/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.3810 - acc: 0.8429Epoch 00014: val_loss improved from 2.38224 to 2.06139, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.4372 - acc: 0.8400 - val_loss: 2.0614 - val_acc: 0.8667\n",
      "Epoch 15/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.0957 - acc: 0.8643Epoch 00015: val_loss did not improve\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0634 - acc: 0.8667 - val_loss: 2.2427 - val_acc: 0.8600\n",
      "Epoch 16/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.3992 - acc: 0.8429Epoch 00016: val_loss improved from 2.06139 to 2.05552, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 2.2393 - acc: 0.8533 - val_loss: 2.0555 - val_acc: 0.8600\n",
      "Epoch 17/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 2.3033 - acc: 0.8571Epoch 00017: val_loss did not improve\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.2572 - acc: 0.8600 - val_loss: 2.1401 - val_acc: 0.8533\n",
      "Epoch 18/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 1.9780 - acc: 0.8714Epoch 00018: val_loss improved from 2.05552 to 1.82672, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.0611 - acc: 0.8667 - val_loss: 1.8267 - val_acc: 0.8867\n",
      "Epoch 19/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 1.9572 - acc: 0.8786Epoch 00019: val_loss improved from 1.82672 to 1.82672, saving model to saved_models/VGG16.weights.best.hdf5\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 1.8267 - acc: 0.8867 - val_loss: 1.8267 - val_acc: 0.8867\n",
      "Epoch 20/20\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 1.9572 - acc: 0.8786  Epoch 00020: val_loss did not improve\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.8267 - acc: 0.8867 - val_loss: 1.8267 - val_acc: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a21fa3828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "n_epochs=20\n",
    "\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/VGG16.weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(train_VGG16, train_targets, \n",
    "          validation_data=(valid_VGG16, valid_targets),\n",
    "          epochs=n_epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.load_weights('saved_models/VGG16.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 88.6667%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "lesion_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_VGG16]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(lesion_predictions)==np.argmax(test_targets, axis=1))/len(lesion_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
